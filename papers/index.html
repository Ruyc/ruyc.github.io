<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="google953878ed50fef583.html"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> PAPERS | Yurong Chen¬†¬†ÈôàÊò±Ëìâ </title> <meta name="author" content="Yurong Chen"> <meta name="description" content="&lt;a href='https://dblp.org/pid/02/41-2.html'&gt;[dblp]&lt;/a&gt;&lt;br&gt; (Œ±Œ≤)indicates alphabetical author order. * indicates equal contribution."> <meta name="keywords" content="Yurong Chen, Algorithmic Game theory, PKU, Peking University, INRIA, INRIA Paris, Chen Yurong"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ruyc.github.io/papers/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Yurong Chen¬†¬†ÈôàÊò±Ëìâ </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">ABOUT </a> </li> <li class="nav-item active"> <a class="nav-link" href="/papers/">PAPERS <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/misc/">MISC </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">PAPERS</h1> <p class="post-description"><a href="https://dblp.org/pid/02/41-2.html" rel="external nofollow noopener" target="_blank">[dblp]</a><br> (Œ±Œ≤)indicates alphabetical author order. * indicates equal contribution.</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <p><br></p> <div class="h2">Journal</div> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#6cd0f5"> <div>Games Econ. Behav.</div> </abbr> </div> <div id="chen2024optimal" class="col-sm-8"> <div class="title">Optimal Private Payoff Manipulation against Commitment in Extensive-form Games</div> <div class="author"> (Œ±Œ≤)¬† <strong>Yurong Chen</strong> ,¬†<a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a>,¬†and¬†<a href="https://yuhao.li/" rel="external nofollow noopener" target="_blank">Yuhao Li</a> </div> <div class="periodical"> <em>Games and Economic Behavior</em>, 2024 </div> <div class="periodical"> A preliminary version of this work was presented at <b>WINE 2022</b>, where it received the <b>Best Student Paper</b> Award üèÜ. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.geb.2024.11.008" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Stackelberg equilibrium describes the optimal strategies of a player, when she (the leader) first credibly commits to a strategy. Her opponent (the follower) will best respond to her commitment. To compute the optimal commitment, a leader must learn enough follower‚Äôs payoff information. The follower can then potentially provide fake information, to induce a different final game outcome that benefits him more than when he truthfully behaves. We study such follower‚Äôs manipulation in extensive-form games. For all four settings considered, we characterize all the inducible game outcomes. We show the polynomial-time tractability of finding the optimal payoff function to misreport. We compare the follower‚Äôs optimal attainable utilities among different settings, with the true game fixed. In particular, one comparison shows that the follower gets no less when the leader‚Äôs strategy space expands from pure strategies to behavioral strategies. Our work completely resolves this follower‚Äôs optimal manipulation problem on extensive-form game trees.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chen2024optimal</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Optimal Private Payoff Manipulation against Commitment in Extensive-form Games}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Games and Economic Behavior}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0899-8256}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.geb.2024.11.008}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0899825624001647}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yurong and Deng, Xiaotie and Li, Yuhao}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Stackelberg equilibrium, Strategic behavior, Private information manipulation, Extensive-form games}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{A preliminary version of this work was presented at &lt;b&gt;WINE 2022&lt;/b&gt;, where it received the &lt;b&gt;Best Student Paper&lt;/b&gt; Award üèÜ. }</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> <p><br></p> <div class="h2">Conference</div> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>ACM EC</div> </abbr> </div> <div id="chen2025learning" class="col-sm-8"> <div class="title">Learning a Stackelberg Leader‚Äôs Incentives from Optimal Commitments</div> <div class="author"> (Œ±Œ≤)¬† <strong>Yurong Chen</strong> ,¬†<a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a>,¬†<a href="https://jgan.xyz/" rel="external nofollow noopener" target="_blank">Jiarui Gan</a>,¬†and¬†<a href="https://yuhao.li/" rel="external nofollow noopener" target="_blank">Yuhao Li</a> </div> <div class="periodical"> <em>In Proceedings of the 26th ACM Conference on Economics and Computation</em>, Stanford University, Stanford, CA, USA, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3736252.3742612" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2302.11829" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/querySSE.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Stackelberg equilibria, as functions of the players‚Äô payoffs, can inversely reveal information about the players‚Äô incentives. In this paper, we study to what extent one can learn about the leader‚Äôs incentives by actively querying the leader‚Äôs optimal commitments against strategically designed followers. We show that, by using polynomially many queries and operations, one can learn a payoff function that is strategically equivalent to the leader‚Äôs, in the sense that: 1) it preserves the leader‚Äôs preference over almost all strategy profiles; and 2) it preserves the set of all possible (strong) Stackelberg equilibria the leader may engage in, considering all possible follower types. As an application, we show that the information acquired by our algorithm is sufficient for a follower to induce the best possible Stackelberg equilibrium by imitating a different follower type. To the best of our knowledge, we are the first to demonstrate that this is possible without knowing the leader‚Äôs payoffs beforehand.A full version of this paper can be found at https://arxiv.org/abs/2302.11829.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chen2025learning</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yurong and Deng, Xiaotie and Gan, Jiarui and Li, Yuhao}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning a Stackelberg Leader's Incentives from Optimal Commitments}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400719431}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3736252.3742612}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3736252.3742612}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 26th ACM Conference on Economics and Computation}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{688}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{stackelberg games, inverse game theory, query complexity, private information manipulation, equilibrium inducing}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Stanford University, Stanford, CA, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{EC '25}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>NeurIPs</div> </abbr> </div> <div id="sun2024mechanism" class="col-sm-8"> <div class="title">Mechanism Design for LLM Fine-tuning with Multiple Reward Models</div> <div class="author"> Haoran Sun ,¬† <strong>Yurong Chen</strong> ,¬†<a href="https://www.microsoft.com/en-us/research/people/siweiwang/" rel="external nofollow noopener" target="_blank">Siwei Wang</a> ,¬†Wei Chen,¬†and¬†<a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a> </div> <div class="periodical"> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2405.16276" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Fine-tuning large language models (LLMs) to aggregate multiple preferences has attracted considerable research attention. With aggregation algorithms advancing, a potential economic scenario arises where fine-tuning services are provided to agents with different preferences. In this context, agents may benefit from strategically misreporting their preferences, which could affect the fine-tuned outcomes. This paper addresses such incentive issues by framing it as a mechanism design problem: an LLM provider determines the fine-tuning objective (training rule) and the pricing scheme (payment rule) for agents. SW-Max training rules. Firstly, we show that under most circumstances, truthful reporting is sub-optimal with simply a training rule, thereby highlighting the necessity of payments. Secondly, we design affine maximizer payment rules that implement SW-Max training rules in dominant-strategy incentive compatibility (DSIC). We characterize sufficient conditions for payment equivalence properties. For a training rule that satisfies these conditions, we have found all the payment rules that implement it in DSIC, as they only differ by a constant term irrelevant to agents‚Äô reports from each other. Thirdly, we demonstrate that our mechanism is approximately DSIC even with perturbed input, showcasing its robustness against the inevitable errors in real-world applications. Experiments on real LLM setups further confirm the practical implications of our results.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">sun2024mechanism</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mechanism Design for LLM Fine-tuning with Multiple Reward Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Haoran and Chen, Yurong and Wang, Siwei and Chen, Wei and Deng, Xiaotie}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2405.16276}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.GT}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>ACM EC</div> </abbr> </div> <div id="chen2024bounded" class="col-sm-8"> <div class="title">Are Bounded Contracts Learnable and Approximately Optimal?</div> <div class="author"> (Œ±Œ≤)¬† <strong>Yurong Chen</strong> ,¬†<a href="https://daleczh.github.io/" rel="external nofollow noopener" target="_blank">Zhaohua Chen</a>,¬†<a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a>,¬†and¬†<a href="https://i.cs.hku.hk/~zhiyi/" rel="external nofollow noopener" target="_blank">Zhiyi Huang</a> </div> <div class="periodical"> <em>In Proceedings of the 25th ACM Conference on Economics and Computation</em>, New Haven, CT, USA, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3670865.3673483" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2402.14486" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>This paper considers the hidden-action model of the principal-agent problem, in which a principal incentivizes an agent to work on a project using a contract. We investigate whether contracts with bounded payments are learnable and approximately optimal. Our main results are two learning algorithms that can find a nearly optimal bounded contract using a polynomial number of queries, under two standard assumptions in the literature: a costlier action for the agent leads to a better outcome distribution for the principal, and the agent‚Äôs cost/effort has diminishing returns. Our polynomial query complexity upper bound shows that standard assumptions are sufficient for achieving an exponential improvement upon the known lower bound for general instances. Unlike the existing algorithms which relied on discretizing the contract space, our algorithms directly learn the underlying outcome distributions. As for the approximate optimality of bounded contracts, we find that they could be far from optimal in terms of multiplicative or additive approximation, but satisfy a notion of mixed approximation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chen2024bounded</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yurong and Chen, Zhaohua and Deng, Xiaotie and Huang, Zhiyi}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400707049}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3670865.3673483}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3670865.3673483}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 25th ACM Conference on Economics and Computation}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{315‚Äì-344}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{30}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{contract theory, query complexity}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{New Haven, CT, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{EC '24}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>NeurIPs</div> </abbr> </div> <div id="duan2023a" class="col-sm-8"> <div class="title">A Scalable Neural Network for DSIC Affine Maximizer Auction Design</div> <div class="author"> <a href="https://zjduan.github.io/" rel="external nofollow noopener" target="_blank">Zhijian Duan</a>,¬†Haoran Sun ,¬† <strong>Yurong Chen</strong> ,¬†and¬†<a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2305.12162" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Automated auction design aims to find empirically high-revenue mechanisms through machine learning. Existing works on multi item auction scenarios can be roughly divided into RegretNet-like and affine maximizer auctions (AMAs) approaches. However, the former cannot strictly ensure dominant strategy incentive compatibility (DSIC), while the latter faces scalability issue due to the large number of allocation candidates. To address these limitations, we propose AMenuNet, a scalable neural network that constructs the AMA parameters (even including the allocation menu) from bidder and item representations. AMenuNet is always DSIC and individually rational (IR) due to the properties of AMAs, and it enhances scalability by generating candidate allocations through a neural network. Additionally, AMenuNet is permutation equivariant, and its number of parameters is independent of auction scale. We conduct extensive experiments to demonstrate that AMenuNet outperforms strong baselines in both contextual and non-contextual multi-item auctions, scales well to larger auctions, generalizes well to different settings, and identifies useful deterministic allocations. Overall, our proposed approach offers an effective solution to automated DSIC auction design, with improved scalability and strong revenue performance in various settings.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">duan2023a</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Duan, Zhijian and Sun, Haoran and Chen, Yurong and Deng, Xiaotie}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Oh, A. and Neumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{56169--56185}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{36}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>KDD</div> </abbr> </div> <div id="li2023learningbased" class="col-sm-8"> <div class="title">Learning-Based Ad Auction Design with Externalities: The Framework and A Matching-Based Approach</div> <div class="author"> Ningyuan Li,¬†Yunxuan Ma,¬†Yang Zhao,¬†<a href="https://zjduan.github.io/" rel="external nofollow noopener" target="_blank">Zhijian Duan</a> ,¬† <strong>Yurong Chen</strong> ,¬†Zhilin Zhang,¬†Jian Xu,¬†Bo Zheng,¬†and¬†<a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a> </div> <div class="periodical"> <em>In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, Long Beach, CA, USA, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3580305.3599403" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2306.07709" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Learning-based ad auctions have increasingly been adopted in online advertising. However, existing approaches neglect externalities, such as the interaction between ads and organic items. In this paper, we propose a general framework, namely Score-Weighted VCG, for designing learning-based ad auctions that account for externalities. The framework decomposes the optimal auction design into two parts: designing a monotone score function and an allocation algorithm, which facilitates data-driven implementation. Theoretical results demonstrate that this framework produces the optimal incentive-compatible and individually rational ad auction under various externality-aware CTR models while being data-efficient and robust. Moreover, we present an approach to implement the proposed framework with a matching-based allocation algorithm. Experiment results on both real-world and synthetic data illustrate the effectiveness of the proposed approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2023learningbased</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Ningyuan and Ma, Yunxuan and Zhao, Yang and Duan, Zhijian and Chen, Yurong and Zhang, Zhilin and Xu, Jian and Zheng, Bo and Deng, Xiaotie}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning-Based Ad Auction Design with Externalities: The Framework and A Matching-Based Approach}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400701030}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3580305.3599403}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3580305.3599403}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1291‚Äì1302}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{multi-slot ad auction, learning-based mechanism design, online advertising, externality}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Long Beach, CA, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{KDD '23}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>ICML</div> </abbr> </div> <div id="chen2023coordinated" class="col-sm-8"> <div class="title">Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets</div> <div class="author"> <strong>Yurong Chen<sup>*</sup></strong> ,¬†Qian Wang<sup>*</sup>,¬†<a href="https://zjduan.github.io/" rel="external nofollow noopener" target="_blank">Zhijian Duan</a>,¬†Haoran Sun,¬†<a href="https://daleczh.github.io/" rel="external nofollow noopener" target="_blank">Zhaohua Chen</a>,¬†Xiang Yan,¬†and¬†<a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a> </div> <div class="periodical"> <em>In Proceedings of the 40th International Conference on Machine Learning</em>, 23‚Äì29 jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2306.07709" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v202/chen23ac/chen23ac.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="/assets/pdf/ICML_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>In online ad markets, a rising number of advertisers are employing bidding agencies to participate in ad auctions. These agencies are specialized in designing online algorithms and bidding on behalf of their clients. Typically, an agency usually has information on multiple advertisers, so she can potentially coordinate bids to help her clients achieve higher utilities than those under independent bidding. In this paper, we study coordinated online bidding algorithms in repeated second-price auctions with budgets. We propose algorithms that guarantee every client a higher utility than the best she can get under independent bidding. We show that these algorithms achieve maximal social welfare and discuss bidders‚Äô incentives to misreport their budgets, in symmetric cases. Our proofs combine the techniques of online learning and equilibrium analysis, overcoming the difficulty of competing with a multi-dimensional benchmark. The performance of our algorithms is further evaluated by experiments on both synthetic and real data. To the best of our knowledge, we are the first to consider bidder coordination in online repeated auctions with constraints.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chen2023coordinated</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen*, Yurong and Wang*, Qian and Duan, Zhijian and Sun, Haoran and Chen, Zhaohua and Yan, Xiang and Deng, Xiaotie}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 40th International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5052--5086}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{202}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{23--29 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>WINE</div> </abbr> <span class="award badge">üèÜ Best Student Paper</span> </div> <div id="chen2022optimal" class="col-sm-8"> <div class="title">Optimal Private Payoff Manipulation Against Commitment in Extensive-form Games</div> <div class="author"> (Œ±Œ≤)¬† <strong>Yurong Chen</strong> ,¬†<a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a>,¬†and¬†<a href="https://yuhao.li/" rel="external nofollow noopener" target="_blank">Yuhao Li</a> </div> <div class="periodical"> <em>In Web and Internet Economics - 18th International Conference, WINE 2022, Troy, NY, USA, December 12-15, 2022, Proceedings</em>, 23‚Äì29 jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2206.13119" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>To take advantage of strategy commitment, a useful tactic of playing games, a leader must learn enough information about the follower‚Äôs payoff function. However, this leaves the follower a chance to provide fake information and influence the final game outcome. Through a carefully contrived payoff function misreported to the learning leader, the follower may induce an outcome that benefits him more, compared to the ones when he truthfully behaves. We study the follower‚Äôs optimal manipulation via such strategic behaviors in extensive-form games. Followers‚Äô different attitudes are taken into account. An optimistic follower maximizes his true utility among all game outcomes that can be induced by some payoff function. A pessimistic follower only considers misreporting payoff functions that induce a unique game outcome. For all the settings considered in this paper, we characterize all the possible game outcomes that can be induced successfully. We show that it is polynomial-time tractable for the follower to find the optimal way of misreporting his private payoff information. Our work completely resolves this follower‚Äôs optimal manipulation problem on an extensive-form game tree. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chen2022optimal</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yurong and Deng, Xiaotie and Li, Yuhao}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Hansen, Kristoffer Arnsfelt and Liu, Tracy Xiao and Malekian, Azarakhsh}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Optimal Private Payoff Manipulation Against Commitment in Extensive-form
                 Games}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Web and Internet Economics - 18th International Conference, {WINE}
                 2022, Troy, NY, USA, December 12-15, 2022, Proceedings}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{13778}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{355}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>IJCAI</div> </abbr> </div> <div id="chen2022on" class="col-sm-8"> <div class="title">On the Convergence of Fictitious Play: A Decomposition Approach</div> <div class="author"> <strong>Yurong Chen</strong> ,¬†<a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a> ,¬†Chenchen Li,¬†David Mguni ,¬†Jun Wang,¬†Xiang Yan,¬†and¬†Yaodong Yang </div> <div class="periodical"> <em>In Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI 2022, Vienna, Austria, 23-29 July 2022</em>, 23‚Äì29 jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.24963/ijcai.2022/26" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2205.01469" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Fictitious play (FP) is one of the most fundamental game-theoretical learning frameworks for computing Nash equilibrium in n-player games, which builds the foundation for modern multi-agent learning algorithms. Although FP has provable convergence guarantees on zero-sum games and potential games, many real-world problems are often a mixture of both and the convergence property of FP has not been fully studied yet. In this paper, we extend the convergence results of FP to the combinations of such games and beyond. Specifically, we derive new conditions for FP to converge by leveraging game decomposition techniques. We further develop a linear relationship unifying cooperation and competition in the sense that these two classes of games are mutually transferable. Finally, we analyze a non-convergent example of FP, the Shapley game, and develop sufficient conditions for FP to converge. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chen2022on</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yurong and Deng, Xiaotie and Li, Chenchen and Mguni, David and Wang, Jun and Yan, Xiang and Yang, Yaodong}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Raedt, Luc De}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On the Convergence of Fictitious Play: {A} Decomposition Approach}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, {IJCAI} 2022, Vienna, Austria, 23-29 July 2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{179--185}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.24963/ijcai.2022/26}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2022/26}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>AAMAS</div> </abbr> </div> <div id="wang2021the" class="col-sm-8"> <div class="title">The Tight Bound for Pure Price of Anarchy in an Extended Miner‚Äôs Dilemma Game</div> <div class="author"> Qian Wang ,¬†and¬† <strong>Yurong Chen</strong> </div> <div class="periodical"> <em>In AAMAS ‚Äô21: 20th International Conference on Autonomous Agents and Multiagent Systems, Virtual Event, United Kingdom, May 3-7, 2021</em>, 23‚Äì29 jul 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.5555/3463952.3464204" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2101.11855" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Pool block withholding attack is performed among mining pools in digital cryptocurrencies, such as Bitcoin. Instead of mining honestly, pools can be incentivized to infiltrate their own miners into other pools. These infiltrators report partial solutions but withhold full solutions, share block rewards but make no contribution to block mining. The block withholding attack among mining pools can be modeled as a non-cooperative game called "the miner‚Äôs dilemm", which reduces effective mining power in the system and leads to potential systemic instability in the blockchain. However, existing literature on the game-theoretic properties of this attack only gives a preliminary analysis, e.g., an upper bound of 3 for the pure price of anarchy (PPoA) in this game, with two pools involved and no miner betraying. Pure price of anarchy is a measurement of how much mining power is wasted in the miner‚Äôs dilemma game. Further tightening its upper bound will bring us more insight into the structure of this game, so as to design mechanisms to reduce the systemic loss caused by mutual attacks. In this paper, we give a tight bound of (1, 2] for the pure price of anarchy. Moreover, we show the tight bound holds in a more general setting, in which infiltrators may betray.We also prove the existence and uniqueness of pure Nash equilibrium in this setting. Inspired by experiments on the game among three mining pools, we conjecture that similar results hold in the N-player miner‚Äôs dilemma game (N&gt;=2).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wang2021the</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Qian and Chen, Yurong}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAMAS '21: 20th International Conference on Autonomous Agents and Multiagent Systems, Virtual Event, United Kingdom, May 3-7, 2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5555/3463952.3464204}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Dignum, Frank and Lomuscio, Alessio and Endriss, Ulle and Now√©, Ann}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1695--1697}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Tight Bound for Pure Price of Anarchy in an Extended Miner's Dilemma Game}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/10.5555/3463952.3464204}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> <p><br></p> <div class="h2">Working Papers</div> <div class="publications"> <h2 class="bibliography">2026</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Arxiv</abbr> </div> <div id="chen2026sampling" class="col-sm-8"> <div class="title">How Sampling Shapes LLM Alignment: From One-Shot Optima to Iterative Dynamics</div> <div class="author"> (Œ±Œ≤)¬† <strong>Yurong Chen</strong> ,¬†Yu He,¬†Michael I. Jordan,¬†and¬†Fan Yao </div> <div class="periodical"> 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2602.12180" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Standard methods for aligning large language models with human preferences learn from pairwise comparisons among sampled candidate responses and regularize toward a reference policy. Despite their effectiveness, the effects of sampling and reference choices are poorly understood theoretically. We investigate these effects through Identity Preference Optimization, a widely used preference alignment framework, and show that proper instance-dependent sampling can yield stronger ranking guarantees, while skewed on-policy sampling can induce excessive concentration under structured preferences. We then analyze iterative alignment dynamics in which the learned policy feeds back into future sampling and reference policies, reflecting a common practice of model-generated preference data. We prove that these dynamics can exhibit persistent oscillations or entropy collapse for certain parameter choices, and characterize regimes that guarantee stability. Our theoretical insights extend to Direct Preference Optimization, indicating the phenomena we captured are common to a broader class of preference-alignment methods. Experiments on real-world preference data validate our findings. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">chen2026sampling</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{How Sampling Shapes LLM Alignment: From One-Shot Optima to Iterative Dynamics}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yurong and He, Yu and Jordan, Michael I. and Yao, Fan}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2602.12180}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.LG}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2026 Yurong Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-NMZVZ2E754"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-NMZVZ2E754");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"ABOUT",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-papers",title:"PAPERS",description:"[dblp]  (\u03b1\u03b2)indicates alphabetical author order. * indicates equal contribution.",section:"Navigation",handler:()=>{window.location.href="/papers/"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-misc",title:"MISC",description:"",section:"Navigation",handler:()=>{window.location.href="/misc/"}},{id:"news-our-paper-on-the-convergence-of-fictitious-play-a-decomposition-approach-link-has-been-accepted-to-ijcai-22-joint-work-with-xiaotie-deng-chenchen-li-david-mguni-jun-wang-xiang-yan-and-yaodong-yang",title:"Our paper On the Convergence of Fictitious Play: A Decomposition Approach [link] has...",description:"",section:"News"},{id:"news-attend-ijcai-22-online-and-present-our-paper-on-the-convergence-of-fictitious-play-a-decomposition-approach-link",title:"Attend IJCAI \u201822 online and present our paper On the Convergence of Fictitious...",description:"",section:"News"},{id:"news-attend-ijtcs-faw-22-online-and-present-our-paper-optimal-private-payoff-manipulation-against-commitment-in-extensive-form-games-link",title:"Attend IJTCS-FAW \u201822 online and present our paper Optimal Private Payoff Manipulation against...",description:"",section:"News"},{id:"news-our-paper-optimal-private-payoff-manipulation-against-commitment-in-extensive-form-games-link-has-been-accepted-to-wine-22-joint-work-with-xiaotie-deng-and-yuhao-li",title:"Our paper Optimal Private Payoff Manipulation against Commitment in Extensive-form Games [link] has...",description:"",section:"News"},{id:"news-our-paper-optimal-private-payoff-manipulation-against-commitment-in-extensive-form-games-link-has-has-won-the-best-student-paper-at-wine-22-joint-work-with-xiaotie-deng-and-yuhao-li",title:"Our paper Optimal Private Payoff Manipulation against Commitment in Extensive-form Games [link] has...",description:"",section:"News"},{id:"news-started-working-at-the-university-of-hong-kong-under-zhiyi-huang-as-a-visiting-researcher-from-feb-2023",title:"Started working at the University of Hong Kong under Zhiyi Huang as a...",description:"",section:"News"},{id:"news-our-paper-coordinated-dynamic-bidding-in-repeated-second-price-auctions-with-budgets-has-been-accepted-to-icml-23-joint-work-with-qian-wang-zhijian-duan-haoran-sun-zhaohua-chen-xiang-yan-and-xiaotie-deng",title:"Our paper Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets has been...",description:"",section:"News"},{id:"news-our-paper-learning-based-ad-auction-design-with-externalities-the-framework-and-a-matching-based-approach-has-been-accepted-to-kdd-23-joint-work-with-ningyuan-li-yunxuan-ma-yang-zhao-zhijian-duan-zhilin-zhang-jian-xu-bo-zheng-and-xiaotie-deng",title:"Our paper Learning-Based Ad Auction Design with Externalities: the Framework and A Matching-Based...",description:"",section:"News"},{id:"news-our-paper-a-scalable-neural-network-for-dsic-affine-maximizer-auction-design-has-been-accepted-to-neurips-23-joint-work-with-zhijian-duan-haoran-sun-and-zhaohua-chen-xiaotie-deng",title:"Our paper A Scalable Neural Network for DSIC Affine Maximizer Auction Design has...",description:"",section:"News"},{id:"news-i-am-honored-to-receive-the-2024-outstanding-graduate-of-peking-university",title:"I am honored to receive the  2024 Outstanding Graduate of Peking University.",description:"",section:"News"},{id:"news-our-paper-are-bounded-contracts-learnable-and-approximately-optimal-has-been-accepted-to-ec-24-joint-work-with-zhaohua-chen-xiaotie-deng-and-zhiyi-huang",title:"Our paper Are Bounded Contracts Learnable and Approximately Optimal? has been accepted to...",description:"",section:"News"},{id:"news-i-am-honored-to-receive-the-2024-outstanding-doctoral-dissertation-award-of-the-school-of-computer-science-peking-university-thesis-title-games-over-learning-agents-private-information-learning-utilization-and-coordination",title:"I am honored to receive the 2024 Outstanding Doctoral Dissertation Award of the...",description:"",section:"News"},{id:"news-today-i-officially-joined-inria-paris-as-a-postdoc-under-the-supervision-of-michael-i-jordan-thrilled-to-embark-on-this-exciting-new-journey",title:"Today, I officially joined Inria Paris as a postdoc, under the supervision of...",description:"",section:"News"},{id:"news-our-paper-mechanism-design-for-llm-fine-tuning-with-multiple-reward-models-has-been-accepted-to-pluralistic-alignment-neurips-2024-workshop-joint-work-with-haoran-sun-siwei-wang-wei-chen-and-xiaotie-deng",title:"Our paper Mechanism Design for LLM Fine-tuning with Multiple Reward Models has been...",description:"",section:"News"},{id:"news-our-paper-optimal-private-payoff-manipulation-against-commitment-in-extensive-form-games-link-has-been-accepted-by-games-and-economic-behavior-joint-work-with-xiaotie-deng-and-yuhao-li",title:"Our paper Optimal Private Payoff Manipulation against Commitment in Extensive-form Games [link] has...",description:"",section:"News"},{id:"news-happy-to-be-invited-to-the-program-committee-of-acm-ec-2025",title:"Happy to be invited to the program committee of ACM EC 2025!",description:"",section:"News"},{id:"news-i-am-honored-to-receive-the-2024-ccf-incentive-program-for-outstanding-doctoral-dissertations-in-theoretical-computer-science-for-my-phd-research-thesis-title-games-over-learning-agents-private-information-learning-utilization-and-coordination",title:"I am honored to receive the 2024 CCF Incentive Program for Outstanding Doctoral...",description:"",section:"News"},{id:"news-our-paper-learning-a-stackelberg-leader-s-incentives-from-optimal-commitments-has-been-accepted-to-ec-25-joint-work-with-jiarui-gan-xiaotie-deng-and-yuhao-li",title:"Our paper Learning a Stackelberg Leader\u2019s Incentives from Optimal Commitments has been accepted...",description:"",section:"News"},{id:"news-happy-to-be-invited-to-the-program-committee-of-wine-2025",title:"Happy to be invited to the program committee of WINE 2025!",description:"",section:"News"},{id:"news-i-am-honored-to-receive-the-nomination-award-for-the-2025-ccf-excellent-doctoral-dissertation-in-intelligent-agents-and-multi-agent-systems-for-my-phd-research-thesis-title-games-over-learning-agents-private-information-learning-utilization-and-coordination",title:"I am honored to receive the Nomination Award for the 2025 CCF Excellent...",description:"",section:"News"},{id:"news-i-will-participate-in-the-1st-uk-workshop-for-junior-researchers-in-economics-and-computation-jecco-2025-on-june-15-16-2025-at-the-university-of-edinburgh-and-present-our-work-see-you-there",title:"I will participate in the 1st UK Workshop for Junior Researchers in Economics...",description:"",section:"News"},{id:"news-i-will-be-visiting-the-university-of-oxford-on-june-17-19-and-present-our-work-there",title:"I will be visiting the University of Oxford on June 17-19 and present...",description:"",section:"News"},{id:"news-our-paper-mechanism-design-for-llm-fine-tuning-with-multiple-reward-models-has-been-accepted-to-neurips-2025-joint-work-with-haoran-sun-siwei-wang-wei-chen-and-xiaotie-deng",title:"Our paper Mechanism Design for LLM Fine-tuning with Multiple Reward Models has been...",description:"",section:"News"},{id:"news-happy-to-be-invited-to-the-program-committee-of-acm-ec-2026",title:"Happy to be invited to the program committee of ACM EC 2026!",description:"",section:"News"},{id:"news-delighted-to-share-that-i-ve-received-a-marie-sk\u0142odowska-curie-actions-msca-postdoctoral-fellowship-acceptance-rate-9-6-hosted-jointly-by-francis-bach-and-michael-i-jordan",title:"Delighted to share that I\u2019ve received a Marie Sk\u0142odowska-Curie Actions (MSCA) postdoctoral fellowship...",description:"",section:"News"},{id:"news-i-will-be-visiting-hong-kong-shenzhen-and-macau-from-feb-26-to-march-7-and-visiting-singapore-from-march-7-to-march-13-feel-free-to-send-me-a-message-and-grab-a-coffee-together",title:"I will be visiting Hong Kong (Shenzhen and Macau) from Feb. 26 to...",description:"",section:"News"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%75%72%6F%6E%67.%63%68%65%6E@%69%6E%72%69%61.%66%72","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0003-0659-7154","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=BxDVsIoAAAAJ","_blank")}},{id:"socials-semantic-scholar",title:"Semantic Scholar",section:"Socials",handler:()=>{window.open("https://www.semanticscholar.org/author/2109184911","_blank")}},{id:"socials-dblp",title:"DBLP",section:"Socials",handler:()=>{window.open("https://dblp.org/pid/02/41-2","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>