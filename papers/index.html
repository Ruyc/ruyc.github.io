<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="google953878ed50fef583.html"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> PAPERS | Yurong Chen  陈昱蓉 </title> <meta name="author" content="Yurong Chen"> <meta name="description" content="&lt;a href='https://dblp.org/pid/02/41-2.html'&gt;[dblp]&lt;/a&gt;&lt;br&gt; (αβ)indicates alphabetical author order. * indicates equal contribution."> <meta name="keywords" content="Yurong Chen, Algorithmic Game theory, PKU, Peking University, INRIA, INRIA Paris, Chen Yurong"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ruyc.github.io/papers/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Yurong Chen  陈昱蓉 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">ABOUT </a> </li> <li class="nav-item active"> <a class="nav-link" href="/papers/">PAPERS <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/misc/">MISC </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">PAPERS</h1> <p class="post-description"><a href="https://dblp.org/pid/02/41-2.html" rel="external nofollow noopener" target="_blank">[dblp]</a><br> (αβ)indicates alphabetical author order. * indicates equal contribution.</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <p><br></p> <div class="h2">Journal</div> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#6cd0f5"> <div>Games Econ. Behav.</div> </abbr> </div> <div id="chen2024optimal" class="col-sm-8"> <div class="title">Optimal Private Payoff Manipulation against Commitment in Extensive-form Games</div> <div class="author"> (αβ)  <strong>Yurong Chen</strong> , <a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a>, and <a href="https://yuhao.li/" rel="external nofollow noopener" target="_blank">Yuhao Li</a> </div> <div class="periodical"> <em>Games and Economic Behavior</em>, 2024 </div> <div class="periodical"> A preliminary version of this work was presented at <b>WINE 2022</b>, where it received the <b>Best Student Paper</b> Award 🏆. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.geb.2024.11.008" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Stackelberg equilibrium describes the optimal strategies of a player, when she (the leader) first credibly commits to a strategy. Her opponent (the follower) will best respond to her commitment. To compute the optimal commitment, a leader must learn enough follower’s payoff information. The follower can then potentially provide fake information, to induce a different final game outcome that benefits him more than when he truthfully behaves. We study such follower’s manipulation in extensive-form games. For all four settings considered, we characterize all the inducible game outcomes. We show the polynomial-time tractability of finding the optimal payoff function to misreport. We compare the follower’s optimal attainable utilities among different settings, with the true game fixed. In particular, one comparison shows that the follower gets no less when the leader’s strategy space expands from pure strategies to behavioral strategies. Our work completely resolves this follower’s optimal manipulation problem on extensive-form game trees.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chen2024optimal</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Optimal Private Payoff Manipulation against Commitment in Extensive-form Games}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Games and Economic Behavior}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0899-8256}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.geb.2024.11.008}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0899825624001647}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yurong and Deng, Xiaotie and Li, Yuhao}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Stackelberg equilibrium, Strategic behavior, Private information manipulation, Extensive-form games}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{A preliminary version of this work was presented at &lt;b&gt;WINE 2022&lt;/b&gt;, where it received the &lt;b&gt;Best Student Paper&lt;/b&gt; Award 🏆. }</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> <p><br></p> <div class="h2">Conference</div> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>ACM EC</div> </abbr> </div> <div id="chen2024bounded" class="col-sm-8"> <div class="title">Are Bounded Contracts Learnable and Approximately Optimal?</div> <div class="author"> (αβ)  <strong>Yurong Chen</strong> , <a href="https://daleczh.github.io/" rel="external nofollow noopener" target="_blank">Zhaohua Chen</a>, <a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a>, and <a href="https://i.cs.hku.hk/~zhiyi/" rel="external nofollow noopener" target="_blank">Zhiyi Huang</a> </div> <div class="periodical"> <em>In Proceedings of the 25th ACM Conference on Economics and Computation</em>, New Haven, CT, USA, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3670865.3673483" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2402.14486" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>This paper considers the hidden-action model of the principal-agent problem, in which a principal incentivizes an agent to work on a project using a contract. We investigate whether contracts with bounded payments are learnable and approximately optimal. Our main results are two learning algorithms that can find a nearly optimal bounded contract using a polynomial number of queries, under two standard assumptions in the literature: a costlier action for the agent leads to a better outcome distribution for the principal, and the agent’s cost/effort has diminishing returns. Our polynomial query complexity upper bound shows that standard assumptions are sufficient for achieving an exponential improvement upon the known lower bound for general instances. Unlike the existing algorithms which relied on discretizing the contract space, our algorithms directly learn the underlying outcome distributions. As for the approximate optimality of bounded contracts, we find that they could be far from optimal in terms of multiplicative or additive approximation, but satisfy a notion of mixed approximation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chen2024bounded</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yurong and Chen, Zhaohua and Deng, Xiaotie and Huang, Zhiyi}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400707049}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3670865.3673483}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3670865.3673483}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 25th ACM Conference on Economics and Computation}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{315–-344}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{30}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{contract theory, query complexity}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{New Haven, CT, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{EC '24}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>NeurIPs</div> </abbr> </div> <div id="duan2023a" class="col-sm-8"> <div class="title">A Scalable Neural Network for DSIC Affine Maximizer Auction Design</div> <div class="author"> <a href="https://zjduan.github.io/" rel="external nofollow noopener" target="_blank">Zhijian Duan</a>, Haoran Sun ,  <strong>Yurong Chen</strong> , and <a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2305.12162" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Automated auction design aims to find empirically high-revenue mechanisms through machine learning. Existing works on multi item auction scenarios can be roughly divided into RegretNet-like and affine maximizer auctions (AMAs) approaches. However, the former cannot strictly ensure dominant strategy incentive compatibility (DSIC), while the latter faces scalability issue due to the large number of allocation candidates. To address these limitations, we propose AMenuNet, a scalable neural network that constructs the AMA parameters (even including the allocation menu) from bidder and item representations. AMenuNet is always DSIC and individually rational (IR) due to the properties of AMAs, and it enhances scalability by generating candidate allocations through a neural network. Additionally, AMenuNet is permutation equivariant, and its number of parameters is independent of auction scale. We conduct extensive experiments to demonstrate that AMenuNet outperforms strong baselines in both contextual and non-contextual multi-item auctions, scales well to larger auctions, generalizes well to different settings, and identifies useful deterministic allocations. Overall, our proposed approach offers an effective solution to automated DSIC auction design, with improved scalability and strong revenue performance in various settings.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">duan2023a</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Duan, Zhijian and Sun, Haoran and Chen, Yurong and Deng, Xiaotie}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Oh, A. and Neumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{56169--56185}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{36}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>KDD</div> </abbr> </div> <div id="li2023learningbased" class="col-sm-8"> <div class="title">Learning-Based Ad Auction Design with Externalities: The Framework and A Matching-Based Approach</div> <div class="author"> Ningyuan Li, Yunxuan Ma, Yang Zhao, <a href="https://zjduan.github.io/" rel="external nofollow noopener" target="_blank">Zhijian Duan</a> ,  <strong>Yurong Chen</strong> , Zhilin Zhang, Jian Xu, Bo Zheng, and <a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a> </div> <div class="periodical"> <em>In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, Long Beach, CA, USA, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3580305.3599403" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2306.07709" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Learning-based ad auctions have increasingly been adopted in online advertising. However, existing approaches neglect externalities, such as the interaction between ads and organic items. In this paper, we propose a general framework, namely Score-Weighted VCG, for designing learning-based ad auctions that account for externalities. The framework decomposes the optimal auction design into two parts: designing a monotone score function and an allocation algorithm, which facilitates data-driven implementation. Theoretical results demonstrate that this framework produces the optimal incentive-compatible and individually rational ad auction under various externality-aware CTR models while being data-efficient and robust. Moreover, we present an approach to implement the proposed framework with a matching-based allocation algorithm. Experiment results on both real-world and synthetic data illustrate the effectiveness of the proposed approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2023learningbased</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Ningyuan and Ma, Yunxuan and Zhao, Yang and Duan, Zhijian and Chen, Yurong and Zhang, Zhilin and Xu, Jian and Zheng, Bo and Deng, Xiaotie}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning-Based Ad Auction Design with Externalities: The Framework and A Matching-Based Approach}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400701030}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3580305.3599403}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3580305.3599403}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1291–1302}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{multi-slot ad auction, learning-based mechanism design, online advertising, externality}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Long Beach, CA, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{KDD '23}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>ICML</div> </abbr> </div> <div id="chen2023coordinated" class="col-sm-8"> <div class="title">Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets</div> <div class="author"> <strong>Yurong Chen<sup>*</sup></strong> , Qian Wang<sup>*</sup>, <a href="https://zjduan.github.io/" rel="external nofollow noopener" target="_blank">Zhijian Duan</a>, Haoran Sun, <a href="https://daleczh.github.io/" rel="external nofollow noopener" target="_blank">Zhaohua Chen</a>, Xiang Yan, and <a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a> </div> <div class="periodical"> <em>In Proceedings of the 40th International Conference on Machine Learning</em>, 23–29 jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2306.07709" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v202/chen23ac/chen23ac.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="/assets/pdf/ICML_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>In online ad markets, a rising number of advertisers are employing bidding agencies to participate in ad auctions. These agencies are specialized in designing online algorithms and bidding on behalf of their clients. Typically, an agency usually has information on multiple advertisers, so she can potentially coordinate bids to help her clients achieve higher utilities than those under independent bidding. In this paper, we study coordinated online bidding algorithms in repeated second-price auctions with budgets. We propose algorithms that guarantee every client a higher utility than the best she can get under independent bidding. We show that these algorithms achieve maximal social welfare and discuss bidders’ incentives to misreport their budgets, in symmetric cases. Our proofs combine the techniques of online learning and equilibrium analysis, overcoming the difficulty of competing with a multi-dimensional benchmark. The performance of our algorithms is further evaluated by experiments on both synthetic and real data. To the best of our knowledge, we are the first to consider bidder coordination in online repeated auctions with constraints.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chen2023coordinated</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen*, Yurong and Wang*, Qian and Duan, Zhijian and Sun, Haoran and Chen, Zhaohua and Yan, Xiang and Deng, Xiaotie}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 40th International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5052--5086}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{202}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{23--29 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>WINE</div> </abbr> <span class="award badge">🏆 Best Student Paper</span> </div> <div id="chen2022optimal" class="col-sm-8"> <div class="title">Optimal Private Payoff Manipulation Against Commitment in Extensive-form Games</div> <div class="author"> (αβ)  <strong>Yurong Chen</strong> , <a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a>, and <a href="https://yuhao.li/" rel="external nofollow noopener" target="_blank">Yuhao Li</a> </div> <div class="periodical"> <em>In Web and Internet Economics - 18th International Conference, WINE 2022, Troy, NY, USA, December 12-15, 2022, Proceedings</em>, 23–29 jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2206.13119" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>To take advantage of strategy commitment, a useful tactic of playing games, a leader must learn enough information about the follower’s payoff function. However, this leaves the follower a chance to provide fake information and influence the final game outcome. Through a carefully contrived payoff function misreported to the learning leader, the follower may induce an outcome that benefits him more, compared to the ones when he truthfully behaves. We study the follower’s optimal manipulation via such strategic behaviors in extensive-form games. Followers’ different attitudes are taken into account. An optimistic follower maximizes his true utility among all game outcomes that can be induced by some payoff function. A pessimistic follower only considers misreporting payoff functions that induce a unique game outcome. For all the settings considered in this paper, we characterize all the possible game outcomes that can be induced successfully. We show that it is polynomial-time tractable for the follower to find the optimal way of misreporting his private payoff information. Our work completely resolves this follower’s optimal manipulation problem on an extensive-form game tree. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chen2022optimal</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yurong and Deng, Xiaotie and Li, Yuhao}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Hansen, Kristoffer Arnsfelt and Liu, Tracy Xiao and Malekian, Azarakhsh}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Optimal Private Payoff Manipulation Against Commitment in Extensive-form
                 Games}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Web and Internet Economics - 18th International Conference, {WINE}
                 2022, Troy, NY, USA, December 12-15, 2022, Proceedings}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{13778}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{355}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>IJCAI</div> </abbr> </div> <div id="chen2022on" class="col-sm-8"> <div class="title">On the Convergence of Fictitious Play: A Decomposition Approach</div> <div class="author"> <strong>Yurong Chen</strong> , <a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a> , Chenchen Li, David Mguni , Jun Wang, Xiang Yan, and Yaodong Yang </div> <div class="periodical"> <em>In Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI 2022, Vienna, Austria, 23-29 July 2022</em>, 23–29 jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.24963/ijcai.2022/26" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2205.01469" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Fictitious play (FP) is one of the most fundamental game-theoretical learning frameworks for computing Nash equilibrium in n-player games, which builds the foundation for modern multi-agent learning algorithms. Although FP has provable convergence guarantees on zero-sum games and potential games, many real-world problems are often a mixture of both and the convergence property of FP has not been fully studied yet. In this paper, we extend the convergence results of FP to the combinations of such games and beyond. Specifically, we derive new conditions for FP to converge by leveraging game decomposition techniques. We further develop a linear relationship unifying cooperation and competition in the sense that these two classes of games are mutually transferable. Finally, we analyze a non-convergent example of FP, the Shapley game, and develop sufficient conditions for FP to converge. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chen2022on</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yurong and Deng, Xiaotie and Li, Chenchen and Mguni, David and Wang, Jun and Yan, Xiang and Yang, Yaodong}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Raedt, Luc De}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On the Convergence of Fictitious Play: {A} Decomposition Approach}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, {IJCAI} 2022, Vienna, Austria, 23-29 July 2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{179--185}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ijcai.org}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.24963/ijcai.2022/26}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2022/26}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>AAMAS</div> </abbr> </div> <div id="wang2021the" class="col-sm-8"> <div class="title">The Tight Bound for Pure Price of Anarchy in an Extended Miner’s Dilemma Game</div> <div class="author"> Qian Wang , and  <strong>Yurong Chen</strong> </div> <div class="periodical"> <em>In AAMAS ’21: 20th International Conference on Autonomous Agents and Multiagent Systems, Virtual Event, United Kingdom, May 3-7, 2021</em>, 23–29 jul 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.5555/3463952.3464204" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2101.11855" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Pool block withholding attack is performed among mining pools in digital cryptocurrencies, such as Bitcoin. Instead of mining honestly, pools can be incentivized to infiltrate their own miners into other pools. These infiltrators report partial solutions but withhold full solutions, share block rewards but make no contribution to block mining. The block withholding attack among mining pools can be modeled as a non-cooperative game called "the miner’s dilemm", which reduces effective mining power in the system and leads to potential systemic instability in the blockchain. However, existing literature on the game-theoretic properties of this attack only gives a preliminary analysis, e.g., an upper bound of 3 for the pure price of anarchy (PPoA) in this game, with two pools involved and no miner betraying. Pure price of anarchy is a measurement of how much mining power is wasted in the miner’s dilemma game. Further tightening its upper bound will bring us more insight into the structure of this game, so as to design mechanisms to reduce the systemic loss caused by mutual attacks. In this paper, we give a tight bound of (1, 2] for the pure price of anarchy. Moreover, we show the tight bound holds in a more general setting, in which infiltrators may betray.We also prove the existence and uniqueness of pure Nash equilibrium in this setting. Inspired by experiments on the game among three mining pools, we conjecture that similar results hold in the N-player miner’s dilemma game (N&gt;=2).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wang2021the</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wang, Qian and Chen, Yurong}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AAMAS '21: 20th International Conference on Autonomous Agents and Multiagent Systems, Virtual Event, United Kingdom, May 3-7, 2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5555/3463952.3464204}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Dignum, Frank and Lomuscio, Alessio and Endriss, Ulle and Nowé, Ann}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1695--1697}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Tight Bound for Pure Price of Anarchy in an Extended Miner's Dilemma Game}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/10.5555/3463952.3464204}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> <p><br></p> <div class="h2">Working Papers</div> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Arxiv</abbr> </div> <div id="sun2024mechanism" class="col-sm-8"> <div class="title">Mechanism Design for LLM Fine-tuning with Multiple Reward Models</div> <div class="author"> Haoran Sun ,  <strong>Yurong Chen</strong> , <a href="https://www.microsoft.com/en-us/research/people/siweiwang/" rel="external nofollow noopener" target="_blank">Siwei Wang</a> , Wei Chen, and <a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a> </div> <div class="periodical"> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2405.16276" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Fine-tuning large language models (LLMs) to aggregate multiple preferences has attracted considerable research attention. With aggregation algorithms advancing, a potential economic scenario arises where fine-tuning services are provided to agents with different preferences. In this context, agents may benefit from strategically misreporting their preferences, which could affect the fine-tuned outcomes. This paper addresses such incentive issues by framing it as a mechanism design problem: an LLM provider determines the fine-tuning objective (training rule) and the pricing scheme (payment rule) for agents. SW-Max training rules. Firstly, we show that under most circumstances, truthful reporting is sub-optimal with simply a training rule, thereby highlighting the necessity of payments. Secondly, we design affine maximizer payment rules that implement SW-Max training rules in dominant-strategy incentive compatibility (DSIC). We characterize sufficient conditions for payment equivalence properties. For a training rule that satisfies these conditions, we have found all the payment rules that implement it in DSIC, as they only differ by a constant term irrelevant to agents’ reports from each other. Thirdly, we demonstrate that our mechanism is approximately DSIC even with perturbed input, showcasing its robustness against the inevitable errors in real-world applications. Experiments on real LLM setups further confirm the practical implications of our results.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">sun2024mechanism</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Mechanism Design for LLM Fine-tuning with Multiple Reward Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sun, Haoran and Chen, Yurong and Wang, Siwei and Chen, Wei and Deng, Xiaotie}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2405.16276}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.GT}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Arxiv</abbr> </div> <div id="chen2023learning" class="col-sm-8"> <div class="title">Learning to Manipulate a Commitment Optimizer</div> <div class="author"> (αβ)  <strong>Yurong Chen</strong> , <a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a>, <a href="https://jgan.xyz/" rel="external nofollow noopener" target="_blank">Jiarui Gan</a>, and <a href="https://yuhao.li/" rel="external nofollow noopener" target="_blank">Yuhao Li</a> </div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2302.11829" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>We consider a Stackelberg scenario where the leader commits optimally based on the follower’s type (i.e., the follower’s payoff function). Despite its rationality, such commitmentoptimizing behavior inadvertently reveals information about the leader’s incentive, especially when one gets access to the leader’s optimal commitments against different follower types. In this paper, we study to what extent one can learn about the leader’s payoff information by actively querying the leader’s optimal commitments. We show that, by using polynomially many queries and operations, a learner can learn a payoff function that is strategically equivalent to the leader’s original payoff function, in the sense that it preserves: 1) the leader’s preference over fairly broad sets of strategy profiles and 2) the set of all possible (strong) Stackelberg equilibria the leader may engage in, considering all possible follower types. As an application, we show that a follower can use the learned information to induce an optimal Stackelberg equilibrium (w.r.t. the follower’s payoff) by imitating a different type, without knowing the leader’s payoff function beforehand. To the best of our knowledge, we are the first to extend this equilibrium inducing problem to the incomplete information setting</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">chen2023learning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning to Manipulate a Commitment Optimizer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yurong and Deng, Xiaotie and Gan, Jiarui and Li, Yuhao}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2302.11829}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.GT}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Yurong Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-NMZVZ2E754"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-NMZVZ2E754");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"ABOUT",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-papers",title:"PAPERS",description:"[dblp]  (\u03b1\u03b2)indicates alphabetical author order. * indicates equal contribution.",section:"Navigation",handler:()=>{window.location.href="/papers/"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-misc",title:"MISC",description:"",section:"Navigation",handler:()=>{window.location.href="/misc/"}},{id:"news-our-paper-on-the-convergence-of-fictitious-play-a-decomposition-approach-link-has-been-accepted-to-ijcai-22-joint-work-with-xiaotie-deng-chenchen-li-david-mguni-jun-wang-xiang-yan-and-yaodong-yang",title:"Our paper On the Convergence of Fictitious Play: A Decomposition Approach [link] has...",description:"",section:"News"},{id:"news-attend-ijcai-22-online-and-present-our-paper-on-the-convergence-of-fictitious-play-a-decomposition-approach-link",title:"Attend IJCAI \u201822 online and present our paper On the Convergence of Fictitious...",description:"",section:"News"},{id:"news-attend-ijtcs-faw-22-online-and-present-our-paper-optimal-private-payoff-manipulation-against-commitment-in-extensive-form-games-link",title:"Attend IJTCS-FAW \u201822 online and present our paper Optimal Private Payoff Manipulation against...",description:"",section:"News"},{id:"news-our-paper-optimal-private-payoff-manipulation-against-commitment-in-extensive-form-games-link-has-been-accepted-to-wine-22-joint-work-with-xiaotie-deng-and-yuhao-li",title:"Our paper Optimal Private Payoff Manipulation against Commitment in Extensive-form Games [link] has...",description:"",section:"News"},{id:"news-our-paper-optimal-private-payoff-manipulation-against-commitment-in-extensive-form-games-link-has-has-won-the-best-student-paper-at-wine-22-joint-work-with-xiaotie-deng-and-yuhao-li",title:"Our paper Optimal Private Payoff Manipulation against Commitment in Extensive-form Games [link] has...",description:"",section:"News"},{id:"news-started-working-at-the-university-of-hong-kong-under-zhiyi-huang-as-a-visiting-researcher-from-feb-2023",title:"Started working at the University of Hong Kong under Zhiyi Huang as a...",description:"",section:"News"},{id:"news-our-paper-coordinated-dynamic-bidding-in-repeated-second-price-auctions-with-budgets-has-been-accepted-to-icml-23-joint-work-with-qian-wang-zhijian-duan-haoran-sun-zhaohua-chen-xiang-yan-and-xiaotie-deng",title:"Our paper Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets has been...",description:"",section:"News"},{id:"news-our-paper-learning-based-ad-auction-design-with-externalities-the-framework-and-a-matching-based-approach-has-been-accepted-to-kdd-23-joint-work-with-ningyuan-li-yunxuan-ma-yang-zhao-zhijian-duan-zhilin-zhang-jian-xu-bo-zheng-and-xiaotie-deng",title:"Our paper Learning-Based Ad Auction Design with Externalities: the Framework and A Matching-Based...",description:"",section:"News"},{id:"news-our-paper-a-scalable-neural-network-for-dsic-affine-maximizer-auction-design-has-been-accepted-to-neurips-23-joint-work-with-zhijian-duan-haoran-sun-and-zhaohua-chen-xiaotie-deng",title:"Our paper A Scalable Neural Network for DSIC Affine Maximizer Auction Design has...",description:"",section:"News"},{id:"news-i-am-honored-to-receive-the-2024-outstanding-graduate-of-peking-university",title:"I am honored to receive the  2024 Outstanding Graduate of Peking University.",description:"",section:"News"},{id:"news-our-paper-are-bounded-contracts-learnable-and-approximately-optimal-has-been-accepted-to-ec-24-joint-work-with-zhaohua-chen-xiaotie-deng-and-zhiyi-huang",title:"Our paper Are Bounded Contracts Learnable and Approximately Optimal? has been accepted to...",description:"",section:"News"},{id:"news-i-am-honored-to-receive-the-2024-outstanding-doctoral-dissertation-award-of-the-school-of-computer-science-peking-university-thesis-title-games-over-learning-agents-private-information-learning-utilization-and-coordination",title:"I am honored to receive the 2024 Outstanding Doctoral Dissertation Award of the...",description:"",section:"News"},{id:"news-today-i-officially-joined-inria-paris-as-a-postdoc-under-the-supervision-of-michael-i-jordan-thrilled-to-embark-on-this-exciting-new-journey",title:"Today, I officially joined Inria Paris as a postdoc, under the supervision of...",description:"",section:"News"},{id:"news-our-paper-mechanism-design-for-llm-fine-tuning-with-multiple-reward-models-has-been-accepted-to-pluralistic-alignment-neurips-2024-workshop-joint-work-with-haoran-sun-siwei-wang-wei-chen-and-xiaotie-deng",title:"Our paper Mechanism Design for LLM Fine-tuning with Multiple Reward Models has been...",description:"",section:"News"},{id:"news-our-paper-optimal-private-payoff-manipulation-against-commitment-in-extensive-form-games-link-has-been-accepted-by-games-and-economic-behavior-joint-work-with-xiaotie-deng-and-yuhao-li",title:"Our paper Optimal Private Payoff Manipulation against Commitment in Extensive-form Games [link] has...",description:"",section:"News"},{id:"news-i-am-honored-to-receive-the-2024-ccf-incentive-program-for-outstanding-doctoral-dissertations-in-theoretical-computer-science-for-my-phd-research-thesis-title-games-over-learning-agents-private-information-learning-utilization-and-coordination",title:"I am honored to receive the 2024 CCF Incentive Program for Outstanding Doctoral...",description:"",section:"News"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%75%72%6F%6E%67.%63%68%65%6E@%69%6E%72%69%61.%66%72","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0003-0659-7154","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=BxDVsIoAAAAJ","_blank")}},{id:"socials-semantic-scholar",title:"Semantic Scholar",section:"Socials",handler:()=>{window.open("https://www.semanticscholar.org/author/2109184911","_blank")}},{id:"socials-dblp",title:"DBLP",section:"Socials",handler:()=>{window.open("https://dblp.org/pid/02/41-2","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>