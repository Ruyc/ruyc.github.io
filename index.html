<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="google953878ed50fef583.html"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Yurong ChenÂ Â é™ˆæ˜±è“‰ </title> <meta name="author" content="Yurong Chen"> <meta name="description" content=""> <meta name="keywords" content="Yurong Chen, Algorithmic Game theory, PKU, Peking University, INRIA, INRIA Paris, Chen Yurong"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ruyc.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">ABOUT <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/papers/">PAPERS </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/misc/">MISC </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Yurong ChenÂ Â é™ˆæ˜±è“‰ </h1> <p class="desc">Inria, Ecole Normale SupÃ©rieure, PSL Research University, France.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/avatar-480.webp 480w,/assets/img/avatar-800.webp 800w,/assets/img/avatar-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/avatar.jpeg?ec6d0d530996fdb46a2f639be2a68935" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="avatar.jpeg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I am a currently a postdoc at <a href="https://sierra-mlopt.github.io/" rel="external nofollow noopener" target="_blank">SIERRA</a>-team, <a href="https://www.inria.fr/en/inria-paris-centre" rel="external nofollow noopener" target="_blank"> INRIA Paris</a>, working with <a href="https://people.eecs.berkeley.edu/~jordan/" rel="external nofollow noopener" target="_blank"> Michael I. Jordan</a>. I obtained my PhD degree in Computer Science at Peking University, where I was advised by <a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a>. I obtained my bachelor degree in Applied Mathematics from Hua Luogeng Honors Class, Beihang University.</p> <p>My current research interest lies in the learning and game theoretic issues in the interaction of strategic and learning agents and how each field can help the other to have better practical implication. For example, I am interested in how to learn playersâ€™ private information from equilibria and how strategic agents can utilize their information advantage to gain profit from interaction.</p> <p>During my PhD, I visited <a href="https://i.cs.hku.hk/~zhiyi/" rel="external nofollow noopener" target="_blank">Zhiyi Huang</a> at the University of Hong Kong from Feb. to Aug. 2023, and from Aug. to Sept. 2024. I worked as an intern at Alimama group from May. to Sept. 2024 on online ad auctions.</p> <p>My email:</p> <p>Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  yurong.chen [at] inria.fr;</p> <p>Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  yurong.chen1909 [at] gmail.com</p> <p>You can also send me a message by clicking on the envelope bottom below.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">May 13, 2025</th> <td> Our paper <strong>Learning a Stackelberg Leaderâ€™s Incentives from Optimal Commitments</strong> has been accepted to <strong>EC â€˜25</strong> (joint work with <a href="https://jgan.xyz/" rel="external nofollow noopener" target="_blank">Jiarui Gan</a>, <a href="https://cfcs.pku.edu.cn/english/people/faculty/xiaotiedeng/index.htm" target="_blank" rel="external nofollow noopener">Xiaotie Deng</a>, and <a href="https://yuhao.li/" rel="external nofollow noopener" target="_blank">Yuhao Li</a>) </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 03, 2025</th> <td> I am honored to receive the <strong><a href="https://mp.weixin.qq.com/s/nVPN44JYK6rGDMuKSChoOQ" rel="external nofollow noopener" target="_blank">2024 CCF Incentive Program for Outstanding Doctoral Dissertations in Theoretical Computer Science</a></strong> for my PhD research (Thesis title: <em>Games over Learning Agents: Private Information Learning, Utilization, and Coordination</em>). </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 22, 2024</th> <td> Our paper <strong>Optimal Private Payoff Manipulation against Commitment in Extensive-form Games</strong> <a class="paper-link" href="https://www.sciencedirect.com/science/article/pii/S0899825624001647" rel="external nofollow noopener" target="_blank">[link]</a> has been accepted by <strong>Games and Economic Behavior</strong> (joint work with <a href="https://cfcs.pku.edu.cn/english/people/faculty/xiaotiedeng/index.htm" target="_blank" rel="external nofollow noopener">Xiaotie Deng</a>, and <a href="https://liyuhao1124.github.io/" rel="external nofollow noopener" target="_blank">Yuhao Li</a>) </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 10, 2024</th> <td> Our paper <a href="https://arxiv.org/abs/2405.16276" rel="external nofollow noopener" target="_blank"><strong>Mechanism Design for LLM Fine-tuning with Multiple Reward Models</strong></a> has been accepted to <strong>Pluralistic Alignment @ NeurIPS 2024 Workshop</strong> (joint work with Haoran Sun, <a href="https://www.microsoft.com/en-us/research/people/siweiwang/" rel="external nofollow noopener" target="_blank"> Siwei Wang</a>, <a href="https://www.microsoft.com/en-us/research/people/weic/" rel="external nofollow noopener" target="_blank">Wei Chen</a>, and <a href="https://cfcs.pku.edu.cn/english/people/faculty/xiaotiedeng/index.htm" target="_blank" rel="external nofollow noopener">Xiaotie Deng</a>) </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 01, 2024</th> <td> Today, I officially joined Inria Paris as a postdoc, under the supervision of <a href="https://people.eecs.berkeley.edu/~jordan/" rel="external nofollow noopener" target="_blank"> Michael I. Jordan </a>. Thrilled to embark on this exciting new journey! </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 07, 2024</th> <td> I am honored to receive the <strong>2024 Outstanding Doctoral Dissertation Award of the School of Computer Science, Peking University</strong> (Thesis title: <em>Games over Learning Agents: Private Information Learning, Utilization, and Coordination</em>). </td> </tr> <tr> <th scope="row" style="width: 20%">May 18, 2024</th> <td> Our paper <a href="https://arxiv.org/abs/2402.14486" rel="external nofollow noopener" target="_blank"><strong>Are Bounded Contracts Learnable and Approximately Optimal?</strong></a> has been accepted to <strong>EC â€˜24</strong> (joint work with <a href="https://daleczh.github.io/" rel="external nofollow noopener" target="_blank">Zhaohua Chen</a>, <a href="https://cfcs.pku.edu.cn/english/people/faculty/xiaotiedeng/index.htm" target="_blank" rel="external nofollow noopener">Xiaotie Deng</a>, and <a href="https://i.cs.hku.hk/~zhiyi/" rel="external nofollow noopener" target="_blank">Zhiyi Huang</a>) </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> (Î±Î²)indicates alphabetical author order. * indicates equal contribution. <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#6cd0f5"> <div>Games Econ. Behav.</div> </abbr> </div> <div id="chen2024optimal" class="col-sm-8"> <div class="title">Optimal Private Payoff Manipulation against Commitment in Extensive-form Games</div> <div class="author"> (Î±Î²)Â  <strong>Yurong Chen</strong> ,Â <a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a>,Â andÂ <a href="https://yuhao.li/" rel="external nofollow noopener" target="_blank">Yuhao Li</a> </div> <div class="periodical"> <em>Games and Economic Behavior</em>, 2024 </div> <div class="periodical"> A preliminary version of this work was presented at <b>WINE 2022</b>, where it received the <b>Best Student Paper</b> Award ğŸ†. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.geb.2024.11.008" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Stackelberg equilibrium describes the optimal strategies of a player, when she (the leader) first credibly commits to a strategy. Her opponent (the follower) will best respond to her commitment. To compute the optimal commitment, a leader must learn enough followerâ€™s payoff information. The follower can then potentially provide fake information, to induce a different final game outcome that benefits him more than when he truthfully behaves. We study such followerâ€™s manipulation in extensive-form games. For all four settings considered, we characterize all the inducible game outcomes. We show the polynomial-time tractability of finding the optimal payoff function to misreport. We compare the followerâ€™s optimal attainable utilities among different settings, with the true game fixed. In particular, one comparison shows that the follower gets no less when the leaderâ€™s strategy space expands from pure strategies to behavioral strategies. Our work completely resolves this followerâ€™s optimal manipulation problem on extensive-form game trees.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">chen2024optimal</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Optimal Private Payoff Manipulation against Commitment in Extensive-form Games}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Games and Economic Behavior}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0899-8256}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.geb.2024.11.008}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0899825624001647}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yurong and Deng, Xiaotie and Li, Yuhao}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Stackelberg equilibrium, Strategic behavior, Private information manipulation, Extensive-form games}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{A preliminary version of this work was presented at &lt;b&gt;WINE 2022&lt;/b&gt;, where it received the &lt;b&gt;Best Student Paper&lt;/b&gt; Award ğŸ†. }</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>ACM EC</div> </abbr> </div> <div id="chen2023learning" class="col-sm-8"> <div class="title">Learning a Stackelberg Leaderâ€™s Incentives from Optimal Commitments</div> <div class="author"> (Î±Î²)Â  <strong>Yurong Chen</strong> ,Â <a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a>,Â <a href="https://jgan.xyz/" rel="external nofollow noopener" target="_blank">Jiarui Gan</a>,Â andÂ <a href="https://yuhao.li/" rel="external nofollow noopener" target="_blank">Yuhao Li</a> </div> <div class="periodical"> <em>In Proceedings of the 26th ACM Conference on Economics and Computation</em>, Stanford University, Stanford, CA, USA, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3736252.3742612" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2302.11829" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Stackelberg equilibria, as functions of the playersâ€™ payoffs, can inversely reveal information about the playersâ€™ incentives. In this paper, we study to what extent one can learn about the leaderâ€™s incentives by actively querying the leaderâ€™s optimal commitments against strategically designed followers. We show that, by using polynomially many queries and operations, one can learn a payoff function that is strategically equivalent to the leaderâ€™s, in the sense that: 1) it preserves the leaderâ€™s preference over almost all strategy profiles; and 2) it preserves the set of all possible (strong) Stackelberg equilibria the leader may engage in, considering all possible follower types. As an application, we show that the information acquired by our algorithm is sufficient for a follower to induce the best possible Stackelberg equilibrium by imitating a different follower type. To the best of our knowledge, we are the first to demonstrate that this is possible without knowing the leaderâ€™s payoffs beforehand.A full version of this paper can be found at https://arxiv.org/abs/2302.11829.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chen2023learning</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yurong and Deng, Xiaotie and Gan, Jiarui and Li, Yuhao}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning a Stackelberg Leader's Incentives from Optimal Commitments}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400719431}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3736252.3742612}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3736252.3742612}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 26th ACM Conference on Economics and Computation}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{688}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{stackelberg games, inverse game theory, query complexity, private information manipulation, equilibrium inducing}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Stanford University, Stanford, CA, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{EC '25}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>ACM EC</div> </abbr> </div> <div id="chen2024bounded" class="col-sm-8"> <div class="title">Are Bounded Contracts Learnable and Approximately Optimal?</div> <div class="author"> (Î±Î²)Â  <strong>Yurong Chen</strong> ,Â <a href="https://daleczh.github.io/" rel="external nofollow noopener" target="_blank">Zhaohua Chen</a>,Â <a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a>,Â andÂ <a href="https://i.cs.hku.hk/~zhiyi/" rel="external nofollow noopener" target="_blank">Zhiyi Huang</a> </div> <div class="periodical"> <em>In Proceedings of the 25th ACM Conference on Economics and Computation</em>, New Haven, CT, USA, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3670865.3673483" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2402.14486" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>This paper considers the hidden-action model of the principal-agent problem, in which a principal incentivizes an agent to work on a project using a contract. We investigate whether contracts with bounded payments are learnable and approximately optimal. Our main results are two learning algorithms that can find a nearly optimal bounded contract using a polynomial number of queries, under two standard assumptions in the literature: a costlier action for the agent leads to a better outcome distribution for the principal, and the agentâ€™s cost/effort has diminishing returns. Our polynomial query complexity upper bound shows that standard assumptions are sufficient for achieving an exponential improvement upon the known lower bound for general instances. Unlike the existing algorithms which relied on discretizing the contract space, our algorithms directly learn the underlying outcome distributions. As for the approximate optimality of bounded contracts, we find that they could be far from optimal in terms of multiplicative or additive approximation, but satisfy a notion of mixed approximation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chen2024bounded</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen, Yurong and Chen, Zhaohua and Deng, Xiaotie and Huang, Zhiyi}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400707049}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3670865.3673483}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3670865.3673483}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 25th ACM Conference on Economics and Computation}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{315â€“-344}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{30}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{contract theory, query complexity}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{New Haven, CT, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{EC '24}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ebb134"> <div>ICML</div> </abbr> </div> <div id="chen2023coordinated" class="col-sm-8"> <div class="title">Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets</div> <div class="author"> <strong>Yurong Chen<sup>*</sup></strong> ,Â Qian Wang<sup>*</sup>,Â <a href="https://zjduan.github.io/" rel="external nofollow noopener" target="_blank">Zhijian Duan</a>,Â Haoran Sun,Â <a href="https://daleczh.github.io/" rel="external nofollow noopener" target="_blank">Zhaohua Chen</a>,Â Xiang Yan,Â andÂ <a href="https://dblp.org/pid/d/XiaotieDeng.html" rel="external nofollow noopener" target="_blank">Xiaotie Deng</a> </div> <div class="periodical"> <em>In Proceedings of the 40th International Conference on Machine Learning</em>, 23â€“29 jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2306.07709" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v202/chen23ac/chen23ac.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="/assets/pdf/ICML_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>In online ad markets, a rising number of advertisers are employing bidding agencies to participate in ad auctions. These agencies are specialized in designing online algorithms and bidding on behalf of their clients. Typically, an agency usually has information on multiple advertisers, so she can potentially coordinate bids to help her clients achieve higher utilities than those under independent bidding. In this paper, we study coordinated online bidding algorithms in repeated second-price auctions with budgets. We propose algorithms that guarantee every client a higher utility than the best she can get under independent bidding. We show that these algorithms achieve maximal social welfare and discuss biddersâ€™ incentives to misreport their budgets, in symmetric cases. Our proofs combine the techniques of online learning and equilibrium analysis, overcoming the difficulty of competing with a multi-dimensional benchmark. The performance of our algorithms is further evaluated by experiments on both synthetic and real data. To the best of our knowledge, we are the first to consider bidder coordination in online repeated auctions with constraints.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">chen2023coordinated</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chen*, Yurong and Wang*, Qian and Duan, Zhijian and Sun, Haoran and Chen, Zhaohua and Yan, Xiang and Deng, Xiaotie}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 40th International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5052--5086}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{202}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{23--29 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%79%75%72%6F%6E%67.%63%68%65%6E@%69%6E%72%69%61.%66%72" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://orcid.org/0000-0003-0659-7154" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=BxDVsIoAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.semanticscholar.org/author/2109184911" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a> <a href="https://dblp.org/pid/02/41-2" title="DBLP" rel="external nofollow noopener" target="_blank"><i class="ai ai-dblp"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 Yurong Chen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-NMZVZ2E754"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-NMZVZ2E754");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"ABOUT",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-papers",title:"PAPERS",description:"[dblp]  (\u03b1\u03b2)indicates alphabetical author order. * indicates equal contribution.",section:"Navigation",handler:()=>{window.location.href="/papers/"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-misc",title:"MISC",description:"",section:"Navigation",handler:()=>{window.location.href="/misc/"}},{id:"news-our-paper-on-the-convergence-of-fictitious-play-a-decomposition-approach-link-has-been-accepted-to-ijcai-22-joint-work-with-xiaotie-deng-chenchen-li-david-mguni-jun-wang-xiang-yan-and-yaodong-yang",title:"Our paper On the Convergence of Fictitious Play: A Decomposition Approach [link] has...",description:"",section:"News"},{id:"news-attend-ijcai-22-online-and-present-our-paper-on-the-convergence-of-fictitious-play-a-decomposition-approach-link",title:"Attend IJCAI \u201822 online and present our paper On the Convergence of Fictitious...",description:"",section:"News"},{id:"news-attend-ijtcs-faw-22-online-and-present-our-paper-optimal-private-payoff-manipulation-against-commitment-in-extensive-form-games-link",title:"Attend IJTCS-FAW \u201822 online and present our paper Optimal Private Payoff Manipulation against...",description:"",section:"News"},{id:"news-our-paper-optimal-private-payoff-manipulation-against-commitment-in-extensive-form-games-link-has-been-accepted-to-wine-22-joint-work-with-xiaotie-deng-and-yuhao-li",title:"Our paper Optimal Private Payoff Manipulation against Commitment in Extensive-form Games [link] has...",description:"",section:"News"},{id:"news-our-paper-optimal-private-payoff-manipulation-against-commitment-in-extensive-form-games-link-has-has-won-the-best-student-paper-at-wine-22-joint-work-with-xiaotie-deng-and-yuhao-li",title:"Our paper Optimal Private Payoff Manipulation against Commitment in Extensive-form Games [link] has...",description:"",section:"News"},{id:"news-started-working-at-the-university-of-hong-kong-under-zhiyi-huang-as-a-visiting-researcher-from-feb-2023",title:"Started working at the University of Hong Kong under Zhiyi Huang as a...",description:"",section:"News"},{id:"news-our-paper-coordinated-dynamic-bidding-in-repeated-second-price-auctions-with-budgets-has-been-accepted-to-icml-23-joint-work-with-qian-wang-zhijian-duan-haoran-sun-zhaohua-chen-xiang-yan-and-xiaotie-deng",title:"Our paper Coordinated Dynamic Bidding in Repeated Second-Price Auctions with Budgets has been...",description:"",section:"News"},{id:"news-our-paper-learning-based-ad-auction-design-with-externalities-the-framework-and-a-matching-based-approach-has-been-accepted-to-kdd-23-joint-work-with-ningyuan-li-yunxuan-ma-yang-zhao-zhijian-duan-zhilin-zhang-jian-xu-bo-zheng-and-xiaotie-deng",title:"Our paper Learning-Based Ad Auction Design with Externalities: the Framework and A Matching-Based...",description:"",section:"News"},{id:"news-our-paper-a-scalable-neural-network-for-dsic-affine-maximizer-auction-design-has-been-accepted-to-neurips-23-joint-work-with-zhijian-duan-haoran-sun-and-zhaohua-chen-xiaotie-deng",title:"Our paper A Scalable Neural Network for DSIC Affine Maximizer Auction Design has...",description:"",section:"News"},{id:"news-i-am-honored-to-receive-the-2024-outstanding-graduate-of-peking-university",title:"I am honored to receive the  2024 Outstanding Graduate of Peking University.",description:"",section:"News"},{id:"news-our-paper-are-bounded-contracts-learnable-and-approximately-optimal-has-been-accepted-to-ec-24-joint-work-with-zhaohua-chen-xiaotie-deng-and-zhiyi-huang",title:"Our paper Are Bounded Contracts Learnable and Approximately Optimal? has been accepted to...",description:"",section:"News"},{id:"news-i-am-honored-to-receive-the-2024-outstanding-doctoral-dissertation-award-of-the-school-of-computer-science-peking-university-thesis-title-games-over-learning-agents-private-information-learning-utilization-and-coordination",title:"I am honored to receive the 2024 Outstanding Doctoral Dissertation Award of the...",description:"",section:"News"},{id:"news-today-i-officially-joined-inria-paris-as-a-postdoc-under-the-supervision-of-michael-i-jordan-thrilled-to-embark-on-this-exciting-new-journey",title:"Today, I officially joined Inria Paris as a postdoc, under the supervision of...",description:"",section:"News"},{id:"news-our-paper-mechanism-design-for-llm-fine-tuning-with-multiple-reward-models-has-been-accepted-to-pluralistic-alignment-neurips-2024-workshop-joint-work-with-haoran-sun-siwei-wang-wei-chen-and-xiaotie-deng",title:"Our paper Mechanism Design for LLM Fine-tuning with Multiple Reward Models has been...",description:"",section:"News"},{id:"news-our-paper-optimal-private-payoff-manipulation-against-commitment-in-extensive-form-games-link-has-been-accepted-by-games-and-economic-behavior-joint-work-with-xiaotie-deng-and-yuhao-li",title:"Our paper Optimal Private Payoff Manipulation against Commitment in Extensive-form Games [link] has...",description:"",section:"News"},{id:"news-i-am-honored-to-receive-the-2024-ccf-incentive-program-for-outstanding-doctoral-dissertations-in-theoretical-computer-science-for-my-phd-research-thesis-title-games-over-learning-agents-private-information-learning-utilization-and-coordination",title:"I am honored to receive the 2024 CCF Incentive Program for Outstanding Doctoral...",description:"",section:"News"},{id:"news-our-paper-learning-a-stackelberg-leader-s-incentives-from-optimal-commitments-has-been-accepted-to-ec-25-joint-work-with-jiarui-gan-xiaotie-deng-and-yuhao-li",title:"Our paper Learning a Stackelberg Leader\u2019s Incentives from Optimal Commitments has been accepted...",description:"",section:"News"},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%75%72%6F%6E%67.%63%68%65%6E@%69%6E%72%69%61.%66%72","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0003-0659-7154","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=BxDVsIoAAAAJ","_blank")}},{id:"socials-semantic-scholar",title:"Semantic Scholar",section:"Socials",handler:()=>{window.open("https://www.semanticscholar.org/author/2109184911","_blank")}},{id:"socials-dblp",title:"DBLP",section:"Socials",handler:()=>{window.open("https://dblp.org/pid/02/41-2","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>